{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 16:25:17.539888: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-12 16:25:18.654374: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential,load_model\n",
    "from keras import layers,Input\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import L1L2\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arry=np.array([[[1,11],[2,12],[3,13],[4,14],[5,15],[6,16],[7,17],[8,18],[9,19],[10,20]],[[1,11],[2,12],[3,13],[4,14],[5,15],[6,16],[7,17],[8,18],[9,19],[10,20]]])\n",
    "# arry=np.array([[[1,2,3,4,5,6,7,8,9,10],[11,12,13,14,15,16,17,18,19,20]],[[1,2,3,4,5,6,7,8,9,10],[11,12,13,14,15,16,17,18,19,20]]])\n",
    "print(arry.shape)\n",
    "print(arry)\n",
    "print(arry.reshape((2,5,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 8192, 2)\n"
     ]
    }
   ],
   "source": [
    "state0=np.load('../Data/new/2gsps/state0.npy')\n",
    "state1=np.load('../Data/new/2gsps/state1.npy')\n",
    "output0=np.zeros((state0.shape[0]))\n",
    "output1=np.ones((state1.shape[0]))\n",
    "print(state0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 8192, 2)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "x=np.vstack((state0,state1))\n",
    "print(x.shape)\n",
    "y=np.hstack((output0,output1))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "st,ed=700,2700\n",
    "x_train, x_test, y_train, y_test = train_test_split(x[:,st:ed,:], y, test_size=0.30, random_state=45)\n",
    "print(x_train.shape)\n",
    "print(y_train.sum())\n",
    "\n",
    "x_train=np.mean(x_train,axis=1)\n",
    "x_test=np.mean(x_test,axis=1)\n",
    "\n",
    "# x_train=x_train.reshape((x_train.shape[0],x_train.shape[1]*2))\n",
    "# x_test=x_test.reshape((x_test.shape[0],x_test.shape[1]*2))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_trainC=x_train.reshape((x_train.shape[0],x_train.shape[1]*2))\n",
    "# x_testC=x_test.reshape((x_test.shape[0],x_test.shape[1]*2))\n",
    "classifier = LogisticRegression(random_state = 42, max_iter=500)\n",
    "classifier.fit(x_train, y_train)\n",
    "print(classifier.score(x_test,y_test))\n",
    "pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVC(decision_function_shape='ovo')\n",
    "model.fit(x_train,y_train)\n",
    "print(model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=list(zip(np.append(np.mean(state0[:,st:ed,0],axis=1),np.mean(state1[:,st:ed,0],axis=1)),np.append(np.mean(state0[:,st:ed,1],axis=1),np.mean(state1[:,st:ed,1],axis=1))))\n",
    "gmm_Y=GaussianMixture(n_components=2,covariance_type='full').fit(Y)\n",
    "bitstring=np.split(gmm_Y.predict(Y),2)\n",
    "print('P(0|0)=',len(bitstring[0][bitstring[0]==0])/len(bitstring[0]))\n",
    "print('P(1|1)=',len(bitstring[1][bitstring[1]==1])/len(bitstring[1]))\n",
    "X=list(zip(np.mean(state0[:,st:ed,0],axis=1),np.mean(state0[:,st:ed,1],axis=1)))\n",
    "gmm_Y_1=GaussianMixture(n_components=1,covariance_type='spherical').fit(X)\n",
    "X=list(zip(np.mean(state1[:,st:ed,0],axis=1),np.mean(state1[:,st:ed,1],axis=1)))\n",
    "gmm_Y_2=GaussianMixture(n_components=1,covariance_type='spherical').fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def arch():\n",
    "    model=Sequential()\n",
    "    model.add(Input(shape=(2)))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    # model.add(Dense(16,activation='relu'))\n",
    "    # # model.add(Dropout(0.8))\n",
    "    # model.add(Dense(16,activation='relu'))\n",
    "    # # model.add(Dropout(0.8))\n",
    "    # model.add(Dense(32,activation='relu'))\n",
    "    # # model.add(Dropout(0.8))\n",
    "    # model.add(Dense(16,activation='relu'))\n",
    "    # # model.add(Dropout(0.8))\n",
    "    # model.add(Dense(4,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    return model\n",
    "arch().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bceloss(y_true, y_pred):\n",
    "    # Clip the prediction value to prevent log(0) error\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # Calculate the weighted binary cross entropy loss\n",
    "    loss = -(0.1 * (y_true * K.log(y_pred)) + 0.9*((1 - y_true) * K.log(1 - y_pred)))\n",
    "    return K.mean(loss, axis=-1)\n",
    "\n",
    "model=arch()\n",
    "model.summary\n",
    "opt=SGD( learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss=binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model_path=\"../Model/NN2/{epoch:02d}-{val_accuracy:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=model.fit(x_train,y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=100,batch_size=16,\n",
    "          callbacks=callbacks_list,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "count1=0\n",
    "y_pred=model.predict(x_test)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if y_test[i]==0:\n",
    "        count+=1\n",
    "        if y_pred[i,0]<0.5:\n",
    "            count1+=1\n",
    "print(count,count1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class GaussianDiscriminantAnalysis:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.class_priors = np.array([np.mean(y == c) for c in self.classes])\n",
    "\n",
    "        self.means = []\n",
    "        self.cov_matrices = []\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            mean_c = np.mean(X_c, axis=0)\n",
    "            cov_matrix_c = np.cov(X_c, rowvar=False)\n",
    "            self.means.append(mean_c)\n",
    "            self.cov_matrices.append(cov_matrix_c)\n",
    "\n",
    "    def predict(self, X):\n",
    "        posteriors = []\n",
    "\n",
    "        for c in self.classes:\n",
    "            class_prior = self.class_priors[int(c)]\n",
    "            mean = self.means[int(c)]\n",
    "            cov_matrix = self.cov_matrices[int(c)]\n",
    "            mvn = multivariate_normal(mean=mean, cov=cov_matrix)\n",
    "            posterior = class_prior * mvn.pdf(X)\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        posteriors = np.array(posteriors).T\n",
    "        predicted_labels = np.argmax(posteriors, axis=1)\n",
    "\n",
    "        return predicted_labels\n",
    "\n",
    "\n",
    "\n",
    "# Initialize and train GDA\n",
    "gda = GaussianDiscriminantAnalysis()\n",
    "gda.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gda.predict(x_train)\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_train)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.254, Max: 0.718\n",
      "Min: 0.500, Max: 0.500\n"
     ]
    }
   ],
   "source": [
    "min,max=-(2**16),(2**16)\n",
    "print('Min: %.3f, Max: %.3f' % (x.min(), x.max()))\n",
    "x= (x-min)/(max-min)\n",
    "print('Min: %.3f, Max: %.3f' % (x.min(), x.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400, 6000)\n",
      "4233.0\n"
     ]
    }
   ],
   "source": [
    "st,ed=1400,4400\n",
    "x_train, x_test, y_train, y_test = train_test_split(x[:,st:ed,:], y, test_size=0.30, random_state=45)\n",
    "x_train=x_train.reshape((x_train.shape[0],6000))\n",
    "x_test=x_test.reshape((x_test.shape[0],6000))\n",
    "print(x_train.shape)\n",
    "print(y_train.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn():\n",
    "    model=Sequential()\n",
    "    model.add(Input(shape=(200,20)))\n",
    "    model.add(layers.LSTM(units=16, return_sequences=True))\n",
    "    model.add(layers.LSTM(units=8, return_sequences=True))\n",
    "    model.add(layers.LSTM(units=4, return_sequences=False))\n",
    "#     model.add(layers.Dense(4,activation='relu'))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def nn():\n",
    "    model=Sequential()\n",
    "    model.add(Input(shape=(6000)))\n",
    "    model.add(layers.Dense(8192,activation='relu'))\n",
    "    model.add(layers.Dense(4096,activation='relu'))\n",
    "    model.add(layers.Dense(2048,activation='relu'))\n",
    "    model.add(layers.Dense(1024,activation='relu'))\n",
    "    model.add(layers.Dense(512,activation='relu'))\n",
    "    model.add(layers.Dense(256,activation='relu'))\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dense(32,activation='relu'))\n",
    "    model.add(layers.Dense(8,activation='relu'))\n",
    "    model.add(layers.Dense(2,activation='relu'))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_41 (Dense)            (None, 8192)              49160192  \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 4096)              33558528  \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 2048)              8390656   \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93882493 (358.13 MB)\n",
      "Trainable params: 93882493 (358.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=rnn()\n",
    "model.summary()\n",
    "opt=SGD( learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss=binary_crossentropy, optimizer=opt, metrics=['accuracy'])\n",
    "model_path=\"../Model/RNN_new/{epoch:02d}-{val_accuracy:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.4957\n",
      "Epoch 1: val_accuracy improved from -inf to 0.49083, saving model to ../Model/RNN_new/01-0.4908.h5\n",
      "33/33 [==============================] - 4s 74ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6932 - val_accuracy: 0.4908\n",
      "Epoch 2/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5047\n",
      "Epoch 2: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 3/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5054\n",
      "Epoch 3: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 4/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 4: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 5/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5064\n",
      "Epoch 5: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 6/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.5029\n",
      "Epoch 6: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 7/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5028\n",
      "Epoch 7: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 8/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5058\n",
      "Epoch 8: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 9/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5067\n",
      "Epoch 9: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 10/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5067\n",
      "Epoch 10: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 11/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5049\n",
      "Epoch 11: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 12/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5038\n",
      "Epoch 12: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 13/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5049\n",
      "Epoch 13: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 14/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5050\n",
      "Epoch 14: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 15/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5039\n",
      "Epoch 15: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 16/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 16: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 17/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5042\n",
      "Epoch 17: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 18/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5054\n",
      "Epoch 18: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 19/200\n",
      "26/33 [======================>.......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5041\n",
      "Epoch 19: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 20/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5080\n",
      "Epoch 20: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 21/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5048\n",
      "Epoch 21: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 22/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 22: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 23/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 23: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 24/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 24: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 25/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5061\n",
      "Epoch 25: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 26/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.5042\n",
      "Epoch 26: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 27/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5033\n",
      "Epoch 27: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 28/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5051\n",
      "Epoch 28: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 29/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.5034\n",
      "Epoch 29: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 30/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5042\n",
      "Epoch 30: val_accuracy did not improve from 0.49083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 31/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.5046\n",
      "Epoch 31: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 32/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5061\n",
      "Epoch 32: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 33/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5013\n",
      "Epoch 33: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 34/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5040\n",
      "Epoch 34: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 35/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5052\n",
      "Epoch 35: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 36/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5071\n",
      "Epoch 36: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 37/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5029\n",
      "Epoch 37: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6932 - val_accuracy: 0.4908\n",
      "Epoch 38/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5050\n",
      "Epoch 38: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 39/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5038\n",
      "Epoch 39: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 40/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5071\n",
      "Epoch 40: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 41/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.5029\n",
      "Epoch 41: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 42/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 42: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 43/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5056\n",
      "Epoch 43: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 44/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 44: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 45/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5059\n",
      "Epoch 45: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 46/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6932 - accuracy: 0.5006\n",
      "Epoch 46: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 47/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5026\n",
      "Epoch 47: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 48/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5051\n",
      "Epoch 48: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 49/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5046\n",
      "Epoch 49: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 50/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5061\n",
      "Epoch 50: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 51/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5035\n",
      "Epoch 51: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 52/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5005\n",
      "Epoch 52: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 53/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5026\n",
      "Epoch 53: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 54/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6932 - accuracy: 0.5025\n",
      "Epoch 54: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 55/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5074\n",
      "Epoch 55: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 56/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.5030\n",
      "Epoch 56: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 57/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5028\n",
      "Epoch 57: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 58/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5028\n",
      "Epoch 58: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 59/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5037\n",
      "Epoch 59: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5016\n",
      "Epoch 60: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 61/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5028\n",
      "Epoch 61: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 62/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.5066\n",
      "Epoch 62: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6935 - val_accuracy: 0.4908\n",
      "Epoch 63/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5027\n",
      "Epoch 63: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 64/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5011\n",
      "Epoch 64: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 65/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.5047\n",
      "Epoch 65: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 66/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5048\n",
      "Epoch 66: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 67/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5028\n",
      "Epoch 67: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 68/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 68: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 69/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 69: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6932 - val_accuracy: 0.4908\n",
      "Epoch 70/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6932 - accuracy: 0.5006\n",
      "Epoch 70: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 71/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5055\n",
      "Epoch 71: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 72/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5048\n",
      "Epoch 72: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 73/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5001\n",
      "Epoch 73: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6932 - val_accuracy: 0.4908\n",
      "Epoch 74/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5055\n",
      "Epoch 74: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 75/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5057\n",
      "Epoch 75: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 76/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5067\n",
      "Epoch 76: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 77/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5003\n",
      "Epoch 77: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6932 - val_accuracy: 0.4908\n",
      "Epoch 78/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5047\n",
      "Epoch 78: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 79/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 79: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 80/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.5022\n",
      "Epoch 80: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 81/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5035\n",
      "Epoch 81: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 82/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.5026\n",
      "Epoch 82: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 83/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5052\n",
      "Epoch 83: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 84/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.5034\n",
      "Epoch 84: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 85/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 85: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 86/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.5034\n",
      "Epoch 86: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 87/200\n",
      "26/33 [======================>.......] - ETA: 0s - loss: 0.6932 - accuracy: 0.5027\n",
      "Epoch 87: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 88/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 88: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 89/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 89: val_accuracy did not improve from 0.49083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 90/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5039\n",
      "Epoch 90: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 91/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 91: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 92/200\n",
      "26/33 [======================>.......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5059\n",
      "Epoch 92: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 93/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.5028\n",
      "Epoch 93: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 94/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5037\n",
      "Epoch 94: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 95/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.5030\n",
      "Epoch 95: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 96/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 96: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 97/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5034\n",
      "Epoch 97: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 98/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5059\n",
      "Epoch 98: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 99/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5050\n",
      "Epoch 99: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 100/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5031\n",
      "Epoch 100: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 101/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5058\n",
      "Epoch 101: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 102/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5063\n",
      "Epoch 102: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 103/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5052\n",
      "Epoch 103: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 104/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 104: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 105/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5049\n",
      "Epoch 105: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 106/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5059\n",
      "Epoch 106: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 107/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5060\n",
      "Epoch 107: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 108/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5039\n",
      "Epoch 108: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6932 - val_accuracy: 0.4908\n",
      "Epoch 109/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5046\n",
      "Epoch 109: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 110/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5064\n",
      "Epoch 110: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 111/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5045\n",
      "Epoch 111: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 112/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.5051\n",
      "Epoch 112: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 113/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 113: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 114/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.5034\n",
      "Epoch 114: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 115/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5057\n",
      "Epoch 115: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 116/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6930 - accuracy: 0.5094\n",
      "Epoch 116: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 117/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5063\n",
      "Epoch 117: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6932 - val_accuracy: 0.4908\n",
      "Epoch 118/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.5035\n",
      "Epoch 118: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5054\n",
      "Epoch 119: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 120/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5032\n",
      "Epoch 120: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 121/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5025\n",
      "Epoch 121: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 122/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.5039\n",
      "Epoch 122: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 123/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5039\n",
      "Epoch 123: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 124/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5038\n",
      "Epoch 124: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 125/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5015\n",
      "Epoch 125: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 126/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 126: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 127/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5064\n",
      "Epoch 127: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 128/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5074\n",
      "Epoch 128: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 129/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5033\n",
      "Epoch 129: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 130/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5022\n",
      "Epoch 130: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 131/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5050\n",
      "Epoch 131: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 132/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5035\n",
      "Epoch 132: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 133/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.5018\n",
      "Epoch 133: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 134/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.5023\n",
      "Epoch 134: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 135/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5019\n",
      "Epoch 135: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 136/200\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5049\n",
      "Epoch 136: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 137/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5061\n",
      "Epoch 137: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 138/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 138: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 139/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5029\n",
      "Epoch 139: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 140/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6933 - accuracy: 0.4818\n",
      "Epoch 140: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.4868 - val_loss: 0.6932 - val_accuracy: 0.4908\n",
      "Epoch 141/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5031\n",
      "Epoch 141: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 142/200\n",
      "26/33 [======================>.......] - ETA: 0s - loss: 0.6931 - accuracy: 0.5044\n",
      "Epoch 142: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 143/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6932 - accuracy: 0.5019\n",
      "Epoch 143: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 144/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5068\n",
      "Epoch 144: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 145/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5054\n",
      "Epoch 145: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 146/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5008\n",
      "Epoch 146: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6932 - val_accuracy: 0.4908\n",
      "Epoch 147/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5035\n",
      "Epoch 147: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 148: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 149/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5051\n",
      "Epoch 149: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 150/200\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.6931 - accuracy: 0.5058\n",
      "Epoch 150: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 151/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 151: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 152/200\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5034\n",
      "Epoch 152: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6932 - val_accuracy: 0.4908\n",
      "Epoch 153/200\n",
      "26/33 [======================>.......] - ETA: 0s - loss: 0.6932 - accuracy: 0.5018\n",
      "Epoch 153: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 154/200\n",
      "27/33 [=======================>......] - ETA: 0s - loss: 0.6933 - accuracy: 0.4984\n",
      "Epoch 154: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6932 - val_accuracy: 0.4908\n",
      "Epoch 155/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5008\n",
      "Epoch 155: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 156/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5070\n",
      "Epoch 156: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 157/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5050\n",
      "Epoch 157: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 158/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5044\n",
      "Epoch 158: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 159/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5028\n",
      "Epoch 159: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 160/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5056\n",
      "Epoch 160: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 161/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5049\n",
      "Epoch 161: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 162/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5046\n",
      "Epoch 162: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 163/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5007\n",
      "Epoch 163: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6932 - val_accuracy: 0.4908\n",
      "Epoch 164/200\n",
      "28/33 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5050\n",
      "Epoch 164: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 165/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5065\n",
      "Epoch 165: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 166/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5030\n",
      "Epoch 166: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 167/200\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5034\n",
      "Epoch 167: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4908\n",
      "Epoch 168/200\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.5029\n",
      "Epoch 168: val_accuracy did not improve from 0.49083\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4908\n",
      "Epoch 169/200\n",
      "14/33 [===========>..................] - ETA: 0s - loss: 0.6932 - accuracy: 0.4992"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/gpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     H\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/readout/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/readout/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/readout/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/readout/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/readout/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/readout/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/readout/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/readout/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/.conda/envs/readout/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/.conda/envs/readout/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    H=model.fit(x_train,y_train,\n",
    "            validation_data=(x_test, y_test),\n",
    "            epochs=200,batch_size=256,\n",
    "            callbacks=callbacks_list,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=100,\n",
    "    max_depth=9,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readout",
   "language": "python",
   "name": "readout"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
