{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential,load_model\n",
    "from keras import layers,Input\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "state0=np.load('../Data/ML/121623/Wstate0_1µs.npy')\n",
    "state1=np.load('../Data/ML/121623/Wstate1_1µs.npy')\n",
    "output0=np.zeros((state0.shape[0]))\n",
    "output1=np.ones((state1.shape[0]))\n",
    "print(state1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "x=np.concatenate((state0,state1),axis=0)\n",
    "print(x.shape)\n",
    "y=np.hstack((output0,output1))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202875740.38027424 -210086248.8832826\n",
      "141376509.25470012 -176239963.77299935\n",
      "0.8778855137159568 0.1086838675974261\n",
      "0.7633342691784727 0.17172748637758317\n"
     ]
    }
   ],
   "source": [
    "print(x[:,0].max(),x[:,0].min())\n",
    "print(x[:,1].max(),x[:,1].min())\n",
    "'''Let min and max be 2^28'''\n",
    "\n",
    "x=(x+(2**28))/(2**29)\n",
    "print(x[:,0].max(),x[:,0].min())\n",
    "print(x[:,1].max(),x[:,1].min())\n",
    "# 202 875 740"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x=np.vstack((state0,state1))\n",
    "print(x.shape)\n",
    "y=np.hstack((output0,output1))\n",
    "print(y.shape)\n",
    "sc = StandardScaler()\n",
    "sc = StandardScaler()\n",
    "x=x[:,700:2700,:].sum(axis=1)\n",
    "X= sc.fit_transform(x)\n",
    "# X_test = sc.transform(x_test)\n",
    "pca = PCA(n_components = 1)\n",
    "X = pca.fit_transform(X)\n",
    "print (pca.explained_variance_)\n",
    "print (pca.explained_variance_ratio_)\n",
    "print (pca.explained_variance_ratio_.cumsum())\n",
    "# X_test = pca.transform(X_test)\n",
    "print(\"X shape: {}\".format(X.shape))\n",
    "x_red =X[y[:] == 1, 0]  # Use y[:, 0] for indexing\n",
    "x_blue = X[y[:] == 0, 0] \n",
    "\n",
    "# Create a histogram with two different colors\n",
    "plt.hist(x_blue, bins=50, color='blue', alpha=0.7, label='y=0')\n",
    "plt.hist(x_red, bins=50, color='red', alpha=0.7, label='y=1')\n",
    "# Add labels and legend\n",
    "plt.xlabel('Scaled values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 2)\n",
      "3515.0\n",
      "(7000, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# st,ed=700,4700\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=45)\n",
    "print(x_train.shape)\n",
    "print(y_train.sum())\n",
    "\n",
    "# x_train=np.mean(x_train,axis=1)\n",
    "# x_test=np.mean(x_test,axis=1)\n",
    "\n",
    "# x_train=x_train.reshape((x_train.shape[0],x_train.shape[1]*2))\n",
    "# x_test=x_test.reshape((x_test.shape[0],x_test.shape[1]*2))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844\n"
     ]
    }
   ],
   "source": [
    "# x_trainC=x_train.reshape((x_train.shape[0],x_train.shape[1]*2))\n",
    "# x_testC=x_test.reshape((x_test.shape[0],x_test.shape[1]*2))\n",
    "classifier = LogisticRegression(random_state = 42, max_iter=500)\n",
    "classifier.fit(x_train, y_train)\n",
    "print(classifier.score(x_test,y_test))\n",
    "pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845\n"
     ]
    }
   ],
   "source": [
    "model=SVC(decision_function_shape='ovo')\n",
    "model.fit(x_train,y_train)\n",
    "print(model.score(x_test,y_test))\n",
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=list(zip(np.append(np.mean(state0[:,st:ed,0],axis=1),np.mean(state1[:,st:ed,0],axis=1)),np.append(np.mean(state0[:,st:ed,1],axis=1),np.mean(state1[:,st:ed,1],axis=1))))\n",
    "gmm_Y=GaussianMixture(n_components=2,covariance_type='full').fit(Y)\n",
    "bitstring=np.split(gmm_Y.predict(Y),2)\n",
    "print('P(0|0)=',len(bitstring[0][bitstring[0]==0])/len(bitstring[0]))\n",
    "print('P(1|1)=',len(bitstring[1][bitstring[1]==1])/len(bitstring[1]))\n",
    "X=list(zip(np.mean(state0[:,st:ed,0],axis=1),np.mean(state0[:,st:ed,1],axis=1)))\n",
    "gmm_Y_1=GaussianMixture(n_components=1,covariance_type='spherical').fit(X)\n",
    "X=list(zip(np.mean(state1[:,st:ed,0],axis=1),np.mean(state1[:,st:ed,1],axis=1)))\n",
    "gmm_Y_2=GaussianMixture(n_components=1,covariance_type='spherical').fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " HiddenLayer1 (Dense)        (None, 8)                 24        \n",
      "                                                                 \n",
      " HiddenLayer2 (Dense)        (None, 4)                 36        \n",
      "                                                                 \n",
      " OuputLayer (Dense)          (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65 (260.00 Byte)\n",
      "Trainable params: 65 (260.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def arch():\n",
    "    model=Sequential()\n",
    "    model.add(Input(shape=(2), name='Input Layer'))\n",
    "    model.add(Dense(8,activation='relu', name='HiddenLayer1'))\n",
    "    model.add(Dense(4,activation='relu', name='HiddenLayer2'))\n",
    "    model.add(Dense(1,activation='sigmoid', name='OuputLayer'))\n",
    "    return model\n",
    "arch().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=arch()\n",
    "model.summary\n",
    "opt=SGD( learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss=binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model_path=\"../Model/NN2/tmp/{epoch:02d}-{val_accuracy:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 1s 3ms/step - loss: 0.6816 - accuracy: 0.5021 - val_loss: 0.6758 - val_accuracy: 0.4957\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.5440 - val_loss: 0.6567 - val_accuracy: 0.6270\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6924 - val_loss: 0.6275 - val_accuracy: 0.6863\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.7511 - val_loss: 0.5923 - val_accuracy: 0.7477\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7747 - val_loss: 0.5571 - val_accuracy: 0.7920\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.8044 - val_loss: 0.5261 - val_accuracy: 0.8027\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.8147 - val_loss: 0.5000 - val_accuracy: 0.8313\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8250 - val_loss: 0.4791 - val_accuracy: 0.8347\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8317 - val_loss: 0.4630 - val_accuracy: 0.8363\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8320 - val_loss: 0.4497 - val_accuracy: 0.8363\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8344 - val_loss: 0.4393 - val_accuracy: 0.8383\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8344 - val_loss: 0.4305 - val_accuracy: 0.8360\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8343 - val_loss: 0.4230 - val_accuracy: 0.8390\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8376 - val_loss: 0.4198 - val_accuracy: 0.8357\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8367 - val_loss: 0.4126 - val_accuracy: 0.8400\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8374 - val_loss: 0.4086 - val_accuracy: 0.8387\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8386 - val_loss: 0.4051 - val_accuracy: 0.8397\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8396 - val_loss: 0.4013 - val_accuracy: 0.8407\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8380 - val_loss: 0.3989 - val_accuracy: 0.8423\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8384 - val_loss: 0.3962 - val_accuracy: 0.8417\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8379 - val_loss: 0.3944 - val_accuracy: 0.8410\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8409 - val_loss: 0.3925 - val_accuracy: 0.8427\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8380 - val_loss: 0.3907 - val_accuracy: 0.8423\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8389 - val_loss: 0.3893 - val_accuracy: 0.8430\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8387 - val_loss: 0.3883 - val_accuracy: 0.8400\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8401 - val_loss: 0.3867 - val_accuracy: 0.8423\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8409 - val_loss: 0.3856 - val_accuracy: 0.8423\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8399 - val_loss: 0.3848 - val_accuracy: 0.8440\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8406 - val_loss: 0.3842 - val_accuracy: 0.8443\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8390 - val_loss: 0.3828 - val_accuracy: 0.8427\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8400 - val_loss: 0.3830 - val_accuracy: 0.8390\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8393 - val_loss: 0.3836 - val_accuracy: 0.8410\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8399 - val_loss: 0.3810 - val_accuracy: 0.8410\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8403 - val_loss: 0.3804 - val_accuracy: 0.8453\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8410 - val_loss: 0.3801 - val_accuracy: 0.8447\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8416 - val_loss: 0.3802 - val_accuracy: 0.8383\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8417 - val_loss: 0.3798 - val_accuracy: 0.8383\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8401 - val_loss: 0.3786 - val_accuracy: 0.8427\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8406 - val_loss: 0.3784 - val_accuracy: 0.8410\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8404 - val_loss: 0.3780 - val_accuracy: 0.8420\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8419 - val_loss: 0.3776 - val_accuracy: 0.8427\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8409 - val_loss: 0.3774 - val_accuracy: 0.8457\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8411 - val_loss: 0.3773 - val_accuracy: 0.8413\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8407 - val_loss: 0.3779 - val_accuracy: 0.8393\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8400 - val_loss: 0.3770 - val_accuracy: 0.8407\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8400 - val_loss: 0.3778 - val_accuracy: 0.8413\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8400 - val_loss: 0.3762 - val_accuracy: 0.8427\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8394 - val_loss: 0.3767 - val_accuracy: 0.8460\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8400 - val_loss: 0.3770 - val_accuracy: 0.8403\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8410 - val_loss: 0.3757 - val_accuracy: 0.8457\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8407 - val_loss: 0.3759 - val_accuracy: 0.8457\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8404 - val_loss: 0.3754 - val_accuracy: 0.8443\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8404 - val_loss: 0.3759 - val_accuracy: 0.8457\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8401 - val_loss: 0.3752 - val_accuracy: 0.8433\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8394 - val_loss: 0.3751 - val_accuracy: 0.8423\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8419 - val_loss: 0.3753 - val_accuracy: 0.8460\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8416 - val_loss: 0.3749 - val_accuracy: 0.8453\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8396 - val_loss: 0.3749 - val_accuracy: 0.8460\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8397 - val_loss: 0.3752 - val_accuracy: 0.8400\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8404 - val_loss: 0.3746 - val_accuracy: 0.8447\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8406 - val_loss: 0.3747 - val_accuracy: 0.8413\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8403 - val_loss: 0.3744 - val_accuracy: 0.8437\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8397 - val_loss: 0.3744 - val_accuracy: 0.8460\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8411 - val_loss: 0.3752 - val_accuracy: 0.8407\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8403 - val_loss: 0.3744 - val_accuracy: 0.8460\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8407 - val_loss: 0.3743 - val_accuracy: 0.8423\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8391 - val_loss: 0.3747 - val_accuracy: 0.8457\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8403 - val_loss: 0.3741 - val_accuracy: 0.8463\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8404 - val_loss: 0.3747 - val_accuracy: 0.8397\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8406 - val_loss: 0.3753 - val_accuracy: 0.8403\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8407 - val_loss: 0.3739 - val_accuracy: 0.8430\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8407 - val_loss: 0.3742 - val_accuracy: 0.8413\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8407 - val_loss: 0.3743 - val_accuracy: 0.8407\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8396 - val_loss: 0.3741 - val_accuracy: 0.8410\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8403 - val_loss: 0.3752 - val_accuracy: 0.8400\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8406 - val_loss: 0.3741 - val_accuracy: 0.8407\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8397 - val_loss: 0.3737 - val_accuracy: 0.8427\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8406 - val_loss: 0.3735 - val_accuracy: 0.8443\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8394 - val_loss: 0.3741 - val_accuracy: 0.8403\n",
      "Epoch 80/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8403 - val_loss: 0.3736 - val_accuracy: 0.8460\n",
      "Epoch 81/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8400 - val_loss: 0.3736 - val_accuracy: 0.8457\n",
      "Epoch 82/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8403 - val_loss: 0.3735 - val_accuracy: 0.8457\n",
      "Epoch 83/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8406 - val_loss: 0.3738 - val_accuracy: 0.8413\n",
      "Epoch 84/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8411 - val_loss: 0.3736 - val_accuracy: 0.8417\n",
      "Epoch 85/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8391 - val_loss: 0.3735 - val_accuracy: 0.8467\n",
      "Epoch 86/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8403 - val_loss: 0.3737 - val_accuracy: 0.8410\n",
      "Epoch 87/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8393 - val_loss: 0.3738 - val_accuracy: 0.8403\n",
      "Epoch 88/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8417 - val_loss: 0.3741 - val_accuracy: 0.8400\n",
      "Epoch 89/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8411 - val_loss: 0.3771 - val_accuracy: 0.8440\n",
      "Epoch 90/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8394 - val_loss: 0.3737 - val_accuracy: 0.8460\n",
      "Epoch 91/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8397 - val_loss: 0.3738 - val_accuracy: 0.8400\n",
      "Epoch 92/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8409 - val_loss: 0.3749 - val_accuracy: 0.8407\n",
      "Epoch 93/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8410 - val_loss: 0.3736 - val_accuracy: 0.8407\n",
      "Epoch 94/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8406 - val_loss: 0.3732 - val_accuracy: 0.8417\n",
      "Epoch 95/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8406 - val_loss: 0.3732 - val_accuracy: 0.8417\n",
      "Epoch 96/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8390 - val_loss: 0.3734 - val_accuracy: 0.8413\n",
      "Epoch 97/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8411 - val_loss: 0.3732 - val_accuracy: 0.8420\n",
      "Epoch 98/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8400 - val_loss: 0.3731 - val_accuracy: 0.8417\n",
      "Epoch 99/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8393 - val_loss: 0.3730 - val_accuracy: 0.8427\n",
      "Epoch 100/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8413 - val_loss: 0.3732 - val_accuracy: 0.8463\n"
     ]
    }
   ],
   "source": [
    "H=model.fit(x_train,y_train,\n",
    "          validation_data=(x_test,y_test),\n",
    "          # validation_split=0.2,\n",
    "          epochs=100,batch_size=64,\n",
    "        #   callbacks=callbacks_list,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Singlechannel\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "N = 100\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"test_accuracy\")\n",
    "plt.title(\"Singlechannel\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('../Model/NN2/tmp/29-0.7716.h5', compile=False)\n",
    "count=0\n",
    "count1=0\n",
    "y_pred=model.predict(x_test)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if y_test[i]==1:\n",
    "        count+=1\n",
    "        if y_pred[i]>=0.5:\n",
    "            count1+=1\n",
    "print(count,count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../x_text.npy',x_test)\n",
    "np.save('../y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class GaussianDiscriminantAnalysis:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.class_priors = np.array([np.mean(y == c) for c in self.classes])\n",
    "\n",
    "        self.means = []\n",
    "        self.cov_matrices = []\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            mean_c = np.mean(X_c, axis=0)\n",
    "            cov_matrix_c = np.cov(X_c, rowvar=False)\n",
    "            self.means.append(mean_c)\n",
    "            self.cov_matrices.append(cov_matrix_c)\n",
    "\n",
    "    def predict(self, X):\n",
    "        posteriors = []\n",
    "\n",
    "        for c in self.classes:\n",
    "            class_prior = self.class_priors[int(c)]\n",
    "            mean = self.means[int(c)]\n",
    "            cov_matrix = self.cov_matrices[int(c)]\n",
    "            mvn = multivariate_normal(mean=mean, cov=cov_matrix)\n",
    "            posterior = class_prior * mvn.pdf(X)\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        posteriors = np.array(posteriors).T\n",
    "        predicted_labels = np.argmax(posteriors, axis=1)\n",
    "\n",
    "        return predicted_labels\n",
    "\n",
    "\n",
    "\n",
    "# Initialize and train GDA\n",
    "gda = GaussianDiscriminantAnalysis()\n",
    "gda.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gda.predict(x_train)\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_train)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fft import fft, rfft\n",
    "from scipy.fft import fftfreq, rfftfreq\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "# def plotCluster(s0I,s0Q,s1I,s1Q,e0I,e0Q,e1I,e1Q,f0I,f0Q,f1I,f1Q,):\n",
    "#     fig = make_subplots(rows=1, cols=1)\n",
    "#     trace0 = go.Scatter(x=s0I, y=s0Q, name='0-500_|0>',mode='markers',line=dict(color='blue'),marker=dict(size=8, symbol='circle-open'))\n",
    "#     trace1 = go.Scatter(x=s1I, y=s1Q, name='0-500_|1>',mode='markers',line=dict(color='red'),marker=dict(size=8,symbol='square-open'))\n",
    "#     trace2 = go.Scatter(x=e0I, y=e0Q, name='500-1000_|0>',mode='markers',line=dict(color='black'),marker=dict(size=8,symbol='star-open'))\n",
    "#     trace3 = go.Scatter(x=e1I, y=e1Q, name='500-1000_|1>',mode='markers',line=dict(color='green'),marker=dict(size=8, symbol='diamond-open'))\n",
    "#     trace4 = go.Scatter(x=f0I, y=f0Q, name='1000-1500_|0>',mode='markers',line=dict(color='orange'),marker=dict(size=8,symbol='square-cross-open'))\n",
    "#     trace5 = go.Scatter(x=f1I, y=f1Q, name='1000-1500_|1>',mode='markers',line=dict(color='pink'),marker=dict(size=8, symbol='diamond-cross-open'))\n",
    "#     fig.add_trace(trace0)\n",
    "#     fig.add_trace(trace1)\n",
    "#     fig.add_trace(trace2)\n",
    "#     fig.add_trace(trace3)\n",
    "#     fig.add_trace(trace4)\n",
    "#     fig.add_trace(trace5)\n",
    "#     # Set the layout\n",
    "#     fig.update_layout(\n",
    "#         title=\"Signals 0-500-1000-1500\",\n",
    "#         xaxis_title=\"I\",\n",
    "#         yaxis_title=\"Q\",\n",
    "#         showlegend=True,\n",
    "#         width=800,  # Set the width of the plot\n",
    "#         height=400,  # Set the height of the plot\n",
    "#     )\n",
    "#     return fig  \n",
    "\n",
    "def plotCluster(s0I,s0Q,s1I,s1Q, name1, name2):\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "    trace0 = go.Scatter(x=s0I, y=s0Q, name=name1,mode='markers',line=dict(color='blue'),marker=dict(size=8, symbol='circle-open'))\n",
    "    trace1 = go.Scatter(x=s1I, y=s1Q, name=name2,mode='markers',line=dict(color='red'),marker=dict(size=8,symbol='square-open'))\n",
    "    fig.add_trace(trace0)\n",
    "    fig.add_trace(trace1)\n",
    "    # Set the layout\n",
    "    fig.update_layout(\n",
    "        title=\"Signals\",\n",
    "        xaxis_title=\"I\",\n",
    "        yaxis_title=\"Q\",\n",
    "        showlegend=True,\n",
    "        width=800,  # Set the width of the plot\n",
    "        height=400,  # Set the height of the plot\n",
    "    )\n",
    "    return fig  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state0_500= np.mean(state0[:,700:1700,:],axis=1)\n",
    "# state1_500= np.mean(state1[:,700:1700,:],axis=1)\n",
    "# state0_1000= np.mean(state0[:,1700:2700,:],axis=1)\n",
    "# state1_1000= np.mean(state1[:,1700:2700,:],axis=1)\n",
    "# state0_1500= np.mean(state0[:,2700:3700,:],axis=1)\n",
    "# state1_1500= np.mean(state1[:,2700:3700,:],axis=1)\n",
    "# state0_4=np.hstack((state0_500,state0_1000,state0_1500))\n",
    "# state1_4=np.hstack((state1_500,state1_1000,state1_1500))\n",
    "\n",
    "# indices = np.arange(6000)\n",
    "# np.random.shuffle(indices)\n",
    "# selected_indices = indices[:1000]\n",
    "# random0 = state0_4[selected_indices]\n",
    "# random1 = state1_4[selected_indices]\n",
    "\n",
    "\n",
    "# print(random0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state0_100= np.sum(state0[:,1500:1700,:],axis=1)\n",
    "state1_100= np.sum(state1[:,1500:1700,:],axis=1)\n",
    "state0_200= np.sum(state0[:,1900:2100,:],axis=1)\n",
    "state1_200= np.sum(state1[:,1900:2100,:],axis=1)\n",
    "state0_300= np.sum(state0[:,2100:2300,:],axis=1)\n",
    "state1_300= np.sum(state1[:,2100:2300,:],axis=1)\n",
    "state0_400= np.sum(state0[:,2300:2500,:],axis=1)\n",
    "state1_400= np.sum(state1[:,2300:2500,:],axis=1)\n",
    "state0_500= np.sum(state0[:,2500:2700,:],axis=1)\n",
    "state1_500= np.sum(state1[:,2500:2700,:],axis=1)\n",
    "state0_4=np.hstack((state0_100,state0_200,state0_300,state0_400,state0_500))\n",
    "state1_4=np.hstack((state1_100,state1_200,state1_300,state1_400,state1_500))\n",
    "\n",
    "indices = np.arange(6000)\n",
    "np.random.shuffle(indices)\n",
    "selected_indices = indices[:1000]\n",
    "random0 = state0_4[selected_indices]\n",
    "random1 = state1_4[selected_indices]\n",
    "\n",
    "\n",
    "print(random0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotCluster(random0[:,0], random0[:,1], random1[:,0], random1[:,1], random0[:, 2], random0[:, 3], random1[:,2], random1[:,3],random0[:, 4], random0[:, 5], random1[:,4], random1[:,5])\n",
    "plotCluster(random0[:,0], random0[:,1], random1[:,0], random1[:,1],'500-600_|0>', '500-600_|1>').show()\n",
    "plotCluster(random0[:, 2], random0[:, 3], random1[:,2], random1[:,3],'600-700_|0>', '600-700_|1>').show()\n",
    "plotCluster(random0[:, 4], random0[:, 5], random1[:,4], random1[:,5],'700-800_|0>', '700-800_|1>').show()\n",
    "plotCluster(random0[:,6], random0[:,7], random1[:,6], random1[:,7],'800-900_|0>', '800-900_|1>').show()\n",
    "plotCluster(random0[:, 8], random0[:, 9], random1[:,8], random1[:,9],'900-1000_|0>', '900-1000_|1>').show()\n",
    "# plotCluster(np.sum(state0[selected_indices,1700:3700, 0],axis=1), np.sum(state0[selected_indices,1700:3700, 1],axis=1), np.sum(state1[selected_indices,1700:3700,0],axis=1), np.sum(state1[selected_indices,1700:3700,1],axis=1),'900-1000_|0>', '900-1000_|1>').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.vstack((state0_4,state1_4))\n",
    "print(x.shape)\n",
    "y=np.hstack((output0,output1))\n",
    "print(y.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=45)\n",
    "print(x_train.shape)\n",
    "print(y_train.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arch():\n",
    "    model=Sequential()\n",
    "    model.add(Input(shape=(10), name='Input Layer'))\n",
    "    model.add(Dense(16,activation='relu', name='HiddenLayer1'))\n",
    "    model.add(Dense(4,activation='relu', name='HiddenLayer2'))\n",
    "    model.add(Dense(1,activation='sigmoid', name='OuputLayer'))\n",
    "    return model\n",
    "arch().summary()\n",
    "\n",
    "model=arch()\n",
    "model.summary\n",
    "opt=SGD( learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss=binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model_path=\"../Model/NN2/tmp/{epoch:02d}-{val_accuracy:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "H=model.fit(x_train,y_train,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,batch_size=64,\n",
    "        #   callbacks=callbacks_list,\n",
    "          verbose=1)\n",
    "# model=load_model('../Model/NN2/tmp/29-0.7716.h5', compile=False)\n",
    "count=0\n",
    "count1=0\n",
    "y_pred=model.predict(x_test)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if y_test[i]==0:\n",
    "        count+=1\n",
    "        if y_pred[i]<=0.5:\n",
    "            count1+=1\n",
    "print(count,count1)\n",
    "\n",
    "count=0\n",
    "count1=0\n",
    "y_pred=model.predict(x_test)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if y_test[i]==1:\n",
    "        count+=1\n",
    "        if y_pred[i]>=0.5:\n",
    "            count1+=1\n",
    "print(count,count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Multichannel\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "N = 100\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"test_accuracy\")\n",
    "plt.title(\"Multichannel\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred > threshold).astype(int)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate percentages\n",
    "conf_mat_percentage = conf_mat / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# Create a heatmap for better visualization with percentages\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_mat_percentage, annot=True, fmt=\".2%\", cmap=\"Blues\", xticklabels=[\"Predicted 0\", \"Predicted 1\"], yticklabels=[\"Actual 0\", \"Actual 1\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix (Percentages)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state0=np.stack((np.load('../Data/neel_readout/120923/state0_15µs_cos.npy').real,np.load('../Data/neel_readout/120923/state0_15µs_cos.npy').imag),axis=1)\n",
    "state1=np.stack((np.load('../Data/neel_readout/120923/state1_15µs_cos.npy').real,np.load('../Data/neel_readout/120923/state1_15µs_cos.npy').imag),axis=1)\n",
    "output0=np.zeros((state0.shape[0]))\n",
    "output1=np.ones((state1.shape[0]))\n",
    "print(state0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.vstack((state0,state1))\n",
    "print(x.shape)\n",
    "y=np.hstack((output0,output1))\n",
    "print(y.shape)\n",
    "\n",
    "min,max= -(2**20),(2**20)\n",
    "print('Min: %.3f, Max: %.3f' % (x.min(), x.max()))\n",
    "x= (x-min)/(max-min)\n",
    "print('Min: %.3f, Max: %.3f' % (x.min(), x.max()))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.80, random_state=45)\n",
    "print(x_train.shape)\n",
    "print(y_train.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X= sc.fit_transform(x)\n",
    "pca = PCA(n_components = 1)\n",
    "X = pca.fit_transform(X)\n",
    "print (pca.explained_variance_)\n",
    "print (pca.explained_variance_ratio_)\n",
    "print (pca.explained_variance_ratio_.cumsum())\n",
    "# X_test = pca.transform(X_test)\n",
    "print(\"X shape: {}\".format(X.shape))\n",
    "x_red =X[y[:] == 1, 0]  # Use y[:, 0] for indexing\n",
    "x_blue = X[y[:] == 0, 0] \n",
    "\n",
    "# Create a histogram with two different colors\n",
    "plt.hist(x_blue, bins=50, color='blue', alpha=0.7, label='y=0')\n",
    "plt.hist(x_red, bins=50, color='red', alpha=0.7, label='y=1')\n",
    "# Add labels and legend\n",
    "plt.xlabel('Scaled values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 42, max_iter=500)\n",
    "classifier.fit(x_train, y_train)\n",
    "print(classifier.score(x_test,y_test))\n",
    "pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVC(decision_function_shape='ovo')\n",
    "model.fit(x_train,y_train)\n",
    "print(model.score(x_test,y_test))\n",
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arch():\n",
    "    model=Sequential()\n",
    "    model.add(Input(shape=(2), name='Input Layer'))\n",
    "    model.add(Dense(8,activation='relu', name='HiddenLayer1'))\n",
    "    model.add(Dense(4,activation='relu', name='HiddenLayer2'))\n",
    "    model.add(Dense(1,activation='sigmoid', name='OuputLayer'))\n",
    "    return model\n",
    "arch().summary()\n",
    "\n",
    "model=arch()\n",
    "model.summary\n",
    "opt=SGD( learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss=binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model_path=\"../Model/NN2/tmp/{epoch:02d}-{val_accuracy:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "H=model.fit(x_train,y_train,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,batch_size=64,\n",
    "        #   callbacks=callbacks_list,\n",
    "          verbose=1)\n",
    "# model=load_model('../Model/NN2/tmp/29-0.7716.h5', compile=False)\n",
    "count=0\n",
    "count1=0\n",
    "y_pred=model.predict(x_test)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if y_test[i]==0:\n",
    "        count+=1\n",
    "        if y_pred[i]<=0.5:\n",
    "            count1+=1\n",
    "print(count,count1)\n",
    "\n",
    "count=0\n",
    "count1=0\n",
    "y_pred=model.predict(x_test)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if y_test[i]==1:\n",
    "        count+=1\n",
    "        if y_pred[i]>=0.5:\n",
    "            count1+=1\n",
    "print(count,count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readout",
   "language": "python",
   "name": "readout"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
