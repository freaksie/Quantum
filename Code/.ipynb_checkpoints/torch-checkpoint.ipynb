{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff6a8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.distributions as distributions\n",
    "import collections, time\n",
    "import h5py, abc, os, pdb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg, signal\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import layers,Input\n",
    "from keras.models import  Sequential,load_model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.regularizers import L1L2, L2\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from package.Graphs import Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa718765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 3000)\n"
     ]
    }
   ],
   "source": [
    "state0=np.load('../Data/neel_readout/Q1_2us/state0.npy')[:,700:3700]\n",
    "state1=np.load('../Data/neel_readout/Q1_2us/state1.npy')[:,700:3700]\n",
    "output0=np.zeros((state0.shape[0]))\n",
    "output1=np.ones((state1.shape[0]))\n",
    "print(state0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9bee908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 3000)\n",
      "(12000,)\n",
      "Min: -684.000, Max: 688.000\n",
      "Min: 0.495, Max: 0.505\n",
      "(8400, 3000)\n",
      "4233.0\n",
      "(8400, 3000)\n",
      "(8400, 300, 1) (3600, 300, 1)\n"
     ]
    }
   ],
   "source": [
    "x=np.vstack((state0,state1))\n",
    "print(x.shape)\n",
    "y=np.hstack((output0,output1))\n",
    "print(y.shape)\n",
    "\n",
    "min,max= -(2**16),(2**16)\n",
    "print('Min: %.3f, Max: %.3f' % (x.min(), x.max()))\n",
    "x= (x-min)/(max-min)\n",
    "print('Min: %.3f, Max: %.3f' % (x.min(), x.max()))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=45)\n",
    "print(x_train.shape)\n",
    "print(y_train.sum())\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train=x_train.reshape((x_train.shape[0],int(x_train.shape[1]/10),10))\n",
    "x_test=x_test.reshape((x_test.shape[0],int(x_test.shape[1]/10),10))\n",
    "x_train=np.mean(x_train,axis=2)\n",
    "x_test=np.mean(x_test,axis=2)\n",
    "x_train=x_train[:,:,None]\n",
    "x_test=x_test[:,:,None]\n",
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fe075eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400, 300, 1) (8400, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "y_train=y_train[:,None]\n",
    "y_test=y_test[:,None]\n",
    "train_ds = data.TensorDataset(torch.tensor(x_train),torch.tensor( y_train))\n",
    "test_ds = data.TensorDataset(torch.tensor(x_test),torch.tensor( y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1de7f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, hidden_size=64, num_layers=2, batch_first=True, dropout=0, bidirectional=True): \n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.dropout = dropout\n",
    "        self.gru = nn.GRU(1, hidden_size, num_layers=num_layers, \n",
    "                            batch_first=batch_first, dropout=dropout, bidirectional=bidirectional)\n",
    "        self.linear = nn.Linear(self.num_directions * hidden_size, 1)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            raise IOError('No GPU')\n",
    "\n",
    "        self.to(self.device)\n",
    "#         self.reset()\n",
    "\n",
    "    def train_gru(self,train_ds, val_ds, optimizer, epochs=30, train_batch_size=128, val_batch_size=2048, seq_size=100000,\n",
    "                load_dict=None, save_path=None, loaded_save_dict=None, tune=False):\n",
    "        train_dl = data.DataLoader(train_ds, batch_size=train_batch_size, shuffle=True)\n",
    "        val_dl = data.DataLoader(test_ds, batch_size=val_batch_size)\n",
    "        save_dict = {}\n",
    "        if loaded_save_dict:\n",
    "            start_epoch = loaded_save_dict['epoch'] + 1\n",
    "            if start_epoch >= epochs:\n",
    "                print('No training. Start epoch larger than epochs')\n",
    "                return None\n",
    "            optimizer.load_state_dict(loaded_save_dict['optimizer_state_dict'])\n",
    "            log = loaded_save_dict['log']\n",
    "            save_dict = loaded_save_dict\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "            log = {}\n",
    "            log['train_loss'], log['train_acc'] = torch.zeros(0), torch.zeros(0)\n",
    "            log['val_loss'], log['val_acc'], log['final_fid'] =  torch.zeros(0), torch.zeros(0), torch.zeros(0)\n",
    "\n",
    "        train_loss, train_acc, val_loss, val_acc, final_fid = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "        for epoch in tqdm(range(start_epoch, epochs), leave=False):\n",
    "            self.train()\n",
    "            train_steps = 0\n",
    "            for inputs, states in train_dl:\n",
    "                num_steps = inputs.shape[1]\n",
    "                h_out = self.init_h(batch_size=len(inputs))\n",
    "                inputs, states = inputs.to(self.device), states.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                logits, h_out = self(inputs_curr, h0)\n",
    "                loss = self.loss_func(logits.view(-1, ERROR_SIZE), states_curr.reshape(-1))\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "\n",
    "                probabilities = self.softmax(logits)\n",
    "                train_acc += (torch.argmax(probabilities.view(-1, ERROR_SIZE), dim=1) == states_curr.reshape(-1)).sum().item()\n",
    "                train_loss += loss.item()    \n",
    "                train_steps += inputs_curr.size(0) * inputs_curr.size(1)\n",
    "\n",
    "                train_loss = train_loss / len(train_dl)\n",
    "                train_acc = train_acc / train_steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f138a60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65860514",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (1510643265.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[31], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    train_gru(train_ds, test_ds, optimizer=optim.Adam(gru.parameters(), epochs=30, train_batch_size=64, val_batch_size=64)\u001b[0m\n\u001b[0m                                                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "gru=GRU()\n",
    "train_gru(train_ds, test_ds, optimizer=optim.Adam(gru.parameters(), epochs=30, train_batch_size=64, val_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc8b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readout",
   "language": "python",
   "name": "readout"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
