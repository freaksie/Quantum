{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 11:42:07.322250: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 11:42:09.073474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1600, 30)\n",
      "Y shape: (1600, 1)\n"
     ]
    }
   ],
   "source": [
    "xTrain=np.load(\"../Data/julyData/trainData.npy\")[:,:30]\n",
    "yTrain=np.load(\"../Data/julyData/trainTarget.npy\")\n",
    "xTest=np.load('../Data/julyData/testData.npy')[:,:30]\n",
    "yTest=np.load(\"../Data/julyData/testTarget.npy\")\n",
    "# xTrain_r=np.reshape(xTrain,(xTrain.shape[0],xTrain.shape[1]*2))\n",
    "# yTrain=np.reshape(yTrain,(yTrain.shape[0]))\n",
    "# xTest_r=np.reshape(xTest,(xTest.shape[0],xTest.shape[1]*2))\n",
    "# yTest=np.reshape(yTest,(yTest.shape[0]))\n",
    "print(\"X shape: {}\\nY shape: {}\".format(xTrain.shape,yTrain.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(xTrain_r)\n",
    "X_test = sc.transform(xTest_r)\n",
    "pca = PCA(n_components = 100)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "print (pca.explained_variance_)\n",
    "print (pca.explained_variance_ratio_)\n",
    "print (pca.explained_variance_ratio_.cumsum())\n",
    "X_test = pca.transform(X_test)\n",
    "print(\"X shape: {}\".format(X_train.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arch():\n",
    "    model=Sequential()\n",
    "    model.add(Input(shape=(30)))\n",
    "    # model.add(Dense(512,activation='relu'))\n",
    "    # # model.add(Dropout(0.8))\n",
    "    # model.add(Dense(256,activation='relu'))\n",
    "    # # model.add(Dropout(0.8))\n",
    "    # model.add(Dense(128,activation='relu'))\n",
    "    # # model.add(Dropout(0.8))\n",
    "    # model.add(Dense(64,activation='relu'))\n",
    "    # # model.add(Dropout(0.8))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    # model.add(Dropout(0.8))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    # model.add(Dropout(0.8))\n",
    "    model.add(Dense(4,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    return model\n",
    "# arch().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                992       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1593 (6.22 KB)\n",
      "Trainable params: 1593 (6.22 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 11:42:34.528249: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model=arch()\n",
    "model.summary()\n",
    "opt=SGD( learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss=binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model_path=\"../Model/NN/{epoch:02d}-{val_accuracy:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7047 - accuracy: 0.5117\n",
      "Epoch 1: val_accuracy improved from -inf to 0.49750, saving model to ../Model/NN/01-0.4975.h5\n",
      "2/2 [==============================] - 1s 212ms/step - loss: 0.7070 - accuracy: 0.5006 - val_loss: 0.7029 - val_accuracy: 0.4975\n",
      "Epoch 2/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7035 - accuracy: 0.4971\n",
      "Epoch 2: val_accuracy did not improve from 0.49750\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7024 - accuracy: 0.5006 - val_loss: 0.6990 - val_accuracy: 0.4975\n",
      "Epoch 3/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6994 - accuracy: 0.5010\n",
      "Epoch 3: val_accuracy did not improve from 0.49750\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6987 - accuracy: 0.5006 - val_loss: 0.6963 - val_accuracy: 0.4975\n",
      "Epoch 4/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6958 - accuracy: 0.5039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/n/nrvora/.conda/envs/readout/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.49750\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6961 - accuracy: 0.5006 - val_loss: 0.6948 - val_accuracy: 0.4950\n",
      "Epoch 5/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6931 - accuracy: 0.5186\n",
      "Epoch 5: val_accuracy did not improve from 0.49750\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6944 - accuracy: 0.5006 - val_loss: 0.6940 - val_accuracy: 0.4975\n",
      "Epoch 6/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6951 - accuracy: 0.4717\n",
      "Epoch 6: val_accuracy improved from 0.49750 to 0.51000, saving model to ../Model/NN/06-0.5100.h5\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6941 - accuracy: 0.4931 - val_loss: 0.6935 - val_accuracy: 0.5100\n",
      "Epoch 7/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 7: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6933 - val_accuracy: 0.4975\n",
      "Epoch 8/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6932 - accuracy: 0.4980\n",
      "Epoch 8: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6933 - val_accuracy: 0.4925\n",
      "Epoch 9/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6933 - accuracy: 0.4834\n",
      "Epoch 9: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6933 - accuracy: 0.4819 - val_loss: 0.6933 - val_accuracy: 0.5025\n",
      "Epoch 10/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6936 - accuracy: 0.4766\n",
      "Epoch 10: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6933 - accuracy: 0.4950 - val_loss: 0.6933 - val_accuracy: 0.4925\n",
      "Epoch 11/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6932 - accuracy: 0.5010\n",
      "Epoch 11: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6933 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.4925\n",
      "Epoch 12/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6932 - accuracy: 0.5039\n",
      "Epoch 12: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4850\n",
      "Epoch 13/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 13: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6931 - accuracy: 0.4971\n",
      "Epoch 14: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6931 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6930 - accuracy: 0.5039\n",
      "Epoch 15: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6931 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5025\n",
      "Epoch 16/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6934 - accuracy: 0.4863\n",
      "Epoch 16: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6931 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5025\n",
      "Epoch 17/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6933 - accuracy: 0.4873\n",
      "Epoch 17: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6931 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5025\n",
      "Epoch 18/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6935 - accuracy: 0.4814\n",
      "Epoch 18: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6931 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5025\n",
      "Epoch 19/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6929 - accuracy: 0.5078\n",
      "Epoch 19: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6931 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5025\n",
      "Epoch 20/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6930 - accuracy: 0.5029\n",
      "Epoch 20: val_accuracy did not improve from 0.51000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6931 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5025\n"
     ]
    }
   ],
   "source": [
    "H=model.fit(xTrain,yTrain,\n",
    "          validation_data=(xTest, yTest),\n",
    "          epochs=20,batch_size=1024,\n",
    "          callbacks=callbacks_list,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 150\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"test_accuracy\")\n",
    "plt.title(\"Qubit State Classification\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readout",
   "language": "python",
   "name": "readout"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
